{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "classical_portfolio_optimization.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIavnP7Pi8Nd",
        "colab_type": "text"
      },
      "source": [
        "# Classical Portfolio Optimization\n",
        "\n",
        "This notebook is used to generate a portfolio of 10 random stocks from the AlphaVantage API and then optimize the portfolio weights using Markowitz theory. The optimization analysis can be performed using 3 years of historical stock data (2014-2017). \n",
        "\n",
        "The returns of the portfolio with and without optimization over a 3 year test timeframe can then be calculated (2017-2020). These results will be used as the baseline in which the optimization performed through supervised and unsupervised learning will be compared.\n",
        "\n",
        "In order to perform the optimization, the stock data must be obtained, the **expected returns** must be calculated, the **variance** of the stock data must be calculated and the **effecient frontier** must be found.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sJkxwCHi8Nn",
        "colab_type": "text"
      },
      "source": [
        "## Obtaining stock data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZtjvdRbp1oJ",
        "colab_type": "text"
      },
      "source": [
        "### Getting stock names\n",
        "The stock names can be found by obtaining an array of all the stocks in the S&P 500 index, generating 10 random numbers and then using those numbers to choose 10 array items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haLUJ9Omi8Nq",
        "colab_type": "code",
        "outputId": "05322480-2289-4000-92bc-8844125882dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Taken from Automating getting the S&P 500 list - Python Programming for Finance p.5\n",
        "# https://pythonprogramming.net/sp500-company-list-python-programming-for-finance/\n",
        "\n",
        "import bs4 as bs\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "def save_sp500_tickers():\n",
        "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
        "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "    tickers = []\n",
        "    for row in table.findAll('tr')[1:]:\n",
        "        ticker = row.findAll('td')[0].text\n",
        "        tickers.append(ticker.strip(\"\\n\"))\n",
        "        \n",
        "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n",
        "        pickle.dump(tickers,f)\n",
        "        \n",
        "    return tickers\n",
        "\n",
        "save_sp500_tickers()\n",
        "    "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MMM',\n",
              " 'ABT',\n",
              " 'ABBV',\n",
              " 'ABMD',\n",
              " 'ACN',\n",
              " 'ATVI',\n",
              " 'ADBE',\n",
              " 'AMD',\n",
              " 'AAP',\n",
              " 'AES',\n",
              " 'AFL',\n",
              " 'A',\n",
              " 'APD',\n",
              " 'AKAM',\n",
              " 'ALK',\n",
              " 'ALB',\n",
              " 'ARE',\n",
              " 'ALXN',\n",
              " 'ALGN',\n",
              " 'ALLE',\n",
              " 'AGN',\n",
              " 'ADS',\n",
              " 'LNT',\n",
              " 'ALL',\n",
              " 'GOOGL',\n",
              " 'GOOG',\n",
              " 'MO',\n",
              " 'AMZN',\n",
              " 'AMCR',\n",
              " 'AEE',\n",
              " 'AAL',\n",
              " 'AEP',\n",
              " 'AXP',\n",
              " 'AIG',\n",
              " 'T',\n",
              " 'AMT',\n",
              " 'AWK',\n",
              " 'AMP',\n",
              " 'ABC',\n",
              " 'AME',\n",
              " 'AMGN',\n",
              " 'APH',\n",
              " 'ADI',\n",
              " 'ANSS',\n",
              " 'ANTM',\n",
              " 'AON',\n",
              " 'AOS',\n",
              " 'APA',\n",
              " 'AIV',\n",
              " 'AAPL',\n",
              " 'AMAT',\n",
              " 'APTV',\n",
              " 'ADM',\n",
              " 'ARNC',\n",
              " 'ANET',\n",
              " 'AJG',\n",
              " 'AIZ',\n",
              " 'ATO',\n",
              " 'ADSK',\n",
              " 'ADP',\n",
              " 'AZO',\n",
              " 'AVB',\n",
              " 'AVY',\n",
              " 'BKR',\n",
              " 'BLL',\n",
              " 'BAC',\n",
              " 'BK',\n",
              " 'BAX',\n",
              " 'BDX',\n",
              " 'BRK.B',\n",
              " 'BBY',\n",
              " 'BIIB',\n",
              " 'BLK',\n",
              " 'BA',\n",
              " 'BKNG',\n",
              " 'BWA',\n",
              " 'BXP',\n",
              " 'BSX',\n",
              " 'BMY',\n",
              " 'AVGO',\n",
              " 'BR',\n",
              " 'BF.B',\n",
              " 'CHRW',\n",
              " 'COG',\n",
              " 'CDNS',\n",
              " 'CPB',\n",
              " 'COF',\n",
              " 'CPRI',\n",
              " 'CAH',\n",
              " 'KMX',\n",
              " 'CCL',\n",
              " 'CAT',\n",
              " 'CBOE',\n",
              " 'CBRE',\n",
              " 'CDW',\n",
              " 'CE',\n",
              " 'CNC',\n",
              " 'CNP',\n",
              " 'CTL',\n",
              " 'CERN',\n",
              " 'CF',\n",
              " 'SCHW',\n",
              " 'CHTR',\n",
              " 'CVX',\n",
              " 'CMG',\n",
              " 'CB',\n",
              " 'CHD',\n",
              " 'CI',\n",
              " 'CINF',\n",
              " 'CTAS',\n",
              " 'CSCO',\n",
              " 'C',\n",
              " 'CFG',\n",
              " 'CTXS',\n",
              " 'CLX',\n",
              " 'CME',\n",
              " 'CMS',\n",
              " 'KO',\n",
              " 'CTSH',\n",
              " 'CL',\n",
              " 'CMCSA',\n",
              " 'CMA',\n",
              " 'CAG',\n",
              " 'CXO',\n",
              " 'COP',\n",
              " 'ED',\n",
              " 'STZ',\n",
              " 'COO',\n",
              " 'CPRT',\n",
              " 'GLW',\n",
              " 'CTVA',\n",
              " 'COST',\n",
              " 'COTY',\n",
              " 'CCI',\n",
              " 'CSX',\n",
              " 'CMI',\n",
              " 'CVS',\n",
              " 'DHI',\n",
              " 'DHR',\n",
              " 'DRI',\n",
              " 'DVA',\n",
              " 'DE',\n",
              " 'DAL',\n",
              " 'XRAY',\n",
              " 'DVN',\n",
              " 'FANG',\n",
              " 'DLR',\n",
              " 'DFS',\n",
              " 'DISCA',\n",
              " 'DISCK',\n",
              " 'DISH',\n",
              " 'DG',\n",
              " 'DLTR',\n",
              " 'D',\n",
              " 'DOV',\n",
              " 'DOW',\n",
              " 'DTE',\n",
              " 'DUK',\n",
              " 'DRE',\n",
              " 'DD',\n",
              " 'DXC',\n",
              " 'ETFC',\n",
              " 'EMN',\n",
              " 'ETN',\n",
              " 'EBAY',\n",
              " 'ECL',\n",
              " 'EIX',\n",
              " 'EW',\n",
              " 'EA',\n",
              " 'EMR',\n",
              " 'ETR',\n",
              " 'EOG',\n",
              " 'EFX',\n",
              " 'EQIX',\n",
              " 'EQR',\n",
              " 'ESS',\n",
              " 'EL',\n",
              " 'EVRG',\n",
              " 'ES',\n",
              " 'RE',\n",
              " 'EXC',\n",
              " 'EXPE',\n",
              " 'EXPD',\n",
              " 'EXR',\n",
              " 'XOM',\n",
              " 'FFIV',\n",
              " 'FB',\n",
              " 'FAST',\n",
              " 'FRT',\n",
              " 'FDX',\n",
              " 'FIS',\n",
              " 'FITB',\n",
              " 'FE',\n",
              " 'FRC',\n",
              " 'FISV',\n",
              " 'FLT',\n",
              " 'FLIR',\n",
              " 'FLS',\n",
              " 'FMC',\n",
              " 'F',\n",
              " 'FTNT',\n",
              " 'FTV',\n",
              " 'FBHS',\n",
              " 'FOXA',\n",
              " 'FOX',\n",
              " 'BEN',\n",
              " 'FCX',\n",
              " 'GPS',\n",
              " 'GRMN',\n",
              " 'IT',\n",
              " 'GD',\n",
              " 'GE',\n",
              " 'GIS',\n",
              " 'GM',\n",
              " 'GPC',\n",
              " 'GILD',\n",
              " 'GL',\n",
              " 'GPN',\n",
              " 'GS',\n",
              " 'GWW',\n",
              " 'HRB',\n",
              " 'HAL',\n",
              " 'HBI',\n",
              " 'HOG',\n",
              " 'HIG',\n",
              " 'HAS',\n",
              " 'HCA',\n",
              " 'PEAK',\n",
              " 'HP',\n",
              " 'HSIC',\n",
              " 'HSY',\n",
              " 'HES',\n",
              " 'HPE',\n",
              " 'HLT',\n",
              " 'HFC',\n",
              " 'HOLX',\n",
              " 'HD',\n",
              " 'HON',\n",
              " 'HRL',\n",
              " 'HST',\n",
              " 'HPQ',\n",
              " 'HUM',\n",
              " 'HBAN',\n",
              " 'HII',\n",
              " 'IEX',\n",
              " 'IDXX',\n",
              " 'INFO',\n",
              " 'ITW',\n",
              " 'ILMN',\n",
              " 'INCY',\n",
              " 'IR',\n",
              " 'INTC',\n",
              " 'ICE',\n",
              " 'IBM',\n",
              " 'IP',\n",
              " 'IPG',\n",
              " 'IFF',\n",
              " 'INTU',\n",
              " 'ISRG',\n",
              " 'IVZ',\n",
              " 'IPGP',\n",
              " 'IQV',\n",
              " 'IRM',\n",
              " 'JKHY',\n",
              " 'J',\n",
              " 'JBHT',\n",
              " 'SJM',\n",
              " 'JNJ',\n",
              " 'JCI',\n",
              " 'JPM',\n",
              " 'JNPR',\n",
              " 'KSU',\n",
              " 'K',\n",
              " 'KEY',\n",
              " 'KEYS',\n",
              " 'KMB',\n",
              " 'KIM',\n",
              " 'KMI',\n",
              " 'KLAC',\n",
              " 'KSS',\n",
              " 'KHC',\n",
              " 'KR',\n",
              " 'LB',\n",
              " 'LHX',\n",
              " 'LH',\n",
              " 'LRCX',\n",
              " 'LW',\n",
              " 'LVS',\n",
              " 'LEG',\n",
              " 'LDOS',\n",
              " 'LEN',\n",
              " 'LLY',\n",
              " 'LNC',\n",
              " 'LIN',\n",
              " 'LYV',\n",
              " 'LKQ',\n",
              " 'LMT',\n",
              " 'L',\n",
              " 'LOW',\n",
              " 'LYB',\n",
              " 'MTB',\n",
              " 'M',\n",
              " 'MRO',\n",
              " 'MPC',\n",
              " 'MKTX',\n",
              " 'MAR',\n",
              " 'MMC',\n",
              " 'MLM',\n",
              " 'MAS',\n",
              " 'MA',\n",
              " 'MKC',\n",
              " 'MXIM',\n",
              " 'MCD',\n",
              " 'MCK',\n",
              " 'MDT',\n",
              " 'MRK',\n",
              " 'MET',\n",
              " 'MTD',\n",
              " 'MGM',\n",
              " 'MCHP',\n",
              " 'MU',\n",
              " 'MSFT',\n",
              " 'MAA',\n",
              " 'MHK',\n",
              " 'TAP',\n",
              " 'MDLZ',\n",
              " 'MNST',\n",
              " 'MCO',\n",
              " 'MS',\n",
              " 'MOS',\n",
              " 'MSI',\n",
              " 'MSCI',\n",
              " 'MYL',\n",
              " 'NDAQ',\n",
              " 'NOV',\n",
              " 'NTAP',\n",
              " 'NFLX',\n",
              " 'NWL',\n",
              " 'NEM',\n",
              " 'NWSA',\n",
              " 'NWS',\n",
              " 'NEE',\n",
              " 'NLSN',\n",
              " 'NKE',\n",
              " 'NI',\n",
              " 'NBL',\n",
              " 'JWN',\n",
              " 'NSC',\n",
              " 'NTRS',\n",
              " 'NOC',\n",
              " 'NLOK',\n",
              " 'NCLH',\n",
              " 'NRG',\n",
              " 'NUE',\n",
              " 'NVDA',\n",
              " 'NVR',\n",
              " 'ORLY',\n",
              " 'OXY',\n",
              " 'ODFL',\n",
              " 'OMC',\n",
              " 'OKE',\n",
              " 'ORCL',\n",
              " 'PCAR',\n",
              " 'PKG',\n",
              " 'PH',\n",
              " 'PAYX',\n",
              " 'PAYC',\n",
              " 'PYPL',\n",
              " 'PNR',\n",
              " 'PBCT',\n",
              " 'PEP',\n",
              " 'PKI',\n",
              " 'PRGO',\n",
              " 'PFE',\n",
              " 'PM',\n",
              " 'PSX',\n",
              " 'PNW',\n",
              " 'PXD',\n",
              " 'PNC',\n",
              " 'PPG',\n",
              " 'PPL',\n",
              " 'PFG',\n",
              " 'PG',\n",
              " 'PGR',\n",
              " 'PLD',\n",
              " 'PRU',\n",
              " 'PEG',\n",
              " 'PSA',\n",
              " 'PHM',\n",
              " 'PVH',\n",
              " 'QRVO',\n",
              " 'PWR',\n",
              " 'QCOM',\n",
              " 'DGX',\n",
              " 'RL',\n",
              " 'RJF',\n",
              " 'RTN',\n",
              " 'O',\n",
              " 'REG',\n",
              " 'REGN',\n",
              " 'RF',\n",
              " 'RSG',\n",
              " 'RMD',\n",
              " 'RHI',\n",
              " 'ROK',\n",
              " 'ROL',\n",
              " 'ROP',\n",
              " 'ROST',\n",
              " 'RCL',\n",
              " 'SPGI',\n",
              " 'CRM',\n",
              " 'SBAC',\n",
              " 'SLB',\n",
              " 'STX',\n",
              " 'SEE',\n",
              " 'SRE',\n",
              " 'NOW',\n",
              " 'SHW',\n",
              " 'SPG',\n",
              " 'SWKS',\n",
              " 'SLG',\n",
              " 'SNA',\n",
              " 'SO',\n",
              " 'LUV',\n",
              " 'SWK',\n",
              " 'SBUX',\n",
              " 'STT',\n",
              " 'STE',\n",
              " 'SYK',\n",
              " 'SIVB',\n",
              " 'SYF',\n",
              " 'SNPS',\n",
              " 'SYY',\n",
              " 'TMUS',\n",
              " 'TROW',\n",
              " 'TTWO',\n",
              " 'TPR',\n",
              " 'TGT',\n",
              " 'TEL',\n",
              " 'FTI',\n",
              " 'TFX',\n",
              " 'TXN',\n",
              " 'TXT',\n",
              " 'TMO',\n",
              " 'TIF',\n",
              " 'TJX',\n",
              " 'TSCO',\n",
              " 'TT',\n",
              " 'TDG',\n",
              " 'TRV',\n",
              " 'TFC',\n",
              " 'TWTR',\n",
              " 'TSN',\n",
              " 'UDR',\n",
              " 'ULTA',\n",
              " 'USB',\n",
              " 'UAA',\n",
              " 'UA',\n",
              " 'UNP',\n",
              " 'UAL',\n",
              " 'UNH',\n",
              " 'UPS',\n",
              " 'URI',\n",
              " 'UTX',\n",
              " 'UHS',\n",
              " 'UNM',\n",
              " 'VFC',\n",
              " 'VLO',\n",
              " 'VAR',\n",
              " 'VTR',\n",
              " 'VRSN',\n",
              " 'VRSK',\n",
              " 'VZ',\n",
              " 'VRTX',\n",
              " 'VIAC',\n",
              " 'V',\n",
              " 'VNO',\n",
              " 'VMC',\n",
              " 'WRB',\n",
              " 'WAB',\n",
              " 'WMT',\n",
              " 'WBA',\n",
              " 'DIS',\n",
              " 'WM',\n",
              " 'WAT',\n",
              " 'WEC',\n",
              " 'WFC',\n",
              " 'WELL',\n",
              " 'WDC',\n",
              " 'WU',\n",
              " 'WRK',\n",
              " 'WY',\n",
              " 'WHR',\n",
              " 'WMB',\n",
              " 'WLTW',\n",
              " 'WYNN',\n",
              " 'XEL',\n",
              " 'XRX',\n",
              " 'XLNX',\n",
              " 'XYL',\n",
              " 'YUM',\n",
              " 'ZBRA',\n",
              " 'ZBH',\n",
              " 'ZION',\n",
              " 'ZTS']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqb9_2M-sczE",
        "colab_type": "text"
      },
      "source": [
        "Next 10 random numbers between 0 and 504 can be generated in order to pick 10 random stock tickers from the list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scqo3IT8sbzV",
        "colab_type": "code",
        "outputId": "36d5fc94-51dc-4df5-be0b-00b37a660b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import random\n",
        "\n",
        "tickers = save_sp500_tickers()\n",
        "print(len(tickers)) # there are actually 505 stocks in the S&P 500, who knew!\n",
        "\n",
        "def getRandomTickers(tickers):\n",
        "  randIndex = []\n",
        "  randTickers = []\n",
        "  for i in range(0,10):\n",
        "    randIndex.append(random.randint(0,504))\n",
        "  for index in randIndex:\n",
        "    randTickers.append(tickers[index])\n",
        "  return randTickers\n",
        "\n",
        "print(getRandomTickers(tickers)) \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "505\n",
            "['ROL', 'DD', 'LRCX', 'WRB', 'TRV', 'COTY', 'GD', 'NRG', 'ORCL', 'AMZN']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp399HE1KSWm",
        "colab_type": "text"
      },
      "source": [
        "Now we can get the names of the tickers in the dataset. \n",
        "\n",
        "The data was extracted from the API using a NodeJS program which obtained daily price and volume data for each stock over a period of 20 years. Due to the failure to extract data for several stocks, the number of stock tickers is not exactly 505, but rather close to 500.\n",
        "\n",
        "We first need to import the data from the csv into a pandas dataframe so that it can be further analyzed.\n",
        "\n",
        "The data is stored in Google Drive and can be accessed via Colab after mounting to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzZHgS2Q5yKU",
        "colab_type": "code",
        "outputId": "a30f9fb2-e95b-44c8-f72f-62f4da8f357f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12XW1J2Q8AQt",
        "colab_type": "text"
      },
      "source": [
        "Now the csv can be imported into a dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl8iqOTR79tt",
        "colab_type": "code",
        "outputId": "28577af1-0c33-4a45-bc3d-e9ffb2661431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "#change directory to where the data is located \n",
        "# %cd drive/My Drive/cap4770-project\n",
        "!pwd\n",
        "\n",
        "#use timer to get process times\n",
        "start_time = time.time()\n",
        "\n",
        "#read csv\n",
        "data = pd.read_csv(\"SP_DAILY_2000-2020.csv\")\n",
        "print(\"read data --- %s seconds ---\" % (time.time() - start_time))\n",
        "print()\n",
        "\n",
        "#preview first 5 lines\n",
        "start_time = time.time()\n",
        "print(data.head())\n",
        "print(\"get head --- %s seconds ---\" % (time.time() - start_time))\n",
        "print()\n",
        "\n",
        "#preview last 5 lines\n",
        "start_time = time.time()\n",
        "print(data.tail())\n",
        "print(\"get tail --- %s seconds ---\" % (time.time() - start_time))\n",
        "print()\n",
        "\n",
        "#get size\n",
        "start_time = time.time()\n",
        "print(\"Size:\", data.size)\n",
        "print(\"get size --- %s seconds ---\" % (time.time() - start_time))\n",
        "print()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c613dcf12751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#read csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SP_DAILY_2000-2020.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"read data --- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'SP_DAILY_2000-2020.csv' does not exist: b'SP_DAILY_2000-2020.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJmvRxRB-SwV",
        "colab_type": "text"
      },
      "source": [
        "Markowitz Analysis requires a vector of expected returns over the period of analysis for all of the stocks in the portfolio as well as the cauculation of the covariance matrix for the stocks. This can then be used to generate the portfolio weight vector omega."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyXNEfyTfAOG",
        "colab_type": "text"
      },
      "source": [
        "The ffn library will be used to retrieve data for the random tickers generated from yahoo finance from March 26, 2010 to March 26, 2015.Then the preliminary Markowitz analysis can be conducted\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2NEX_egcLH",
        "colab_type": "code",
        "outputId": "5c4a24c4-d8bb-4180-99cb-331658721856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "#setup\n",
        "%matplotlib inline\n",
        "\n",
        "#need to add these packages to requirements.txt\n",
        "!pip install empyrical ffn PyPortfolioOpt\n",
        "\n",
        "#taken from https://github.com/Poseyy/MarketAnalysis/blob/master/portfolios/PortfolioAnalysis.ipynb\n",
        "import ffn \n",
        "from empyrical import alpha_beta\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt import discrete_allocation\n",
        "import matplotlib as pyplot\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: empyrical in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "Requirement already satisfied: ffn in /usr/local/lib/python3.6/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyPortfolioOpt in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pandas>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from empyrical) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from empyrical) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.15.1 in /usr/local/lib/python3.6/dist-packages (from empyrical) (1.4.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.6/dist-packages (from empyrical) (0.7.4)\n",
            "Requirement already satisfied: decorator>=4 in /usr/local/lib/python3.6/dist-packages (from ffn) (4.4.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.6/dist-packages (from ffn) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.6/dist-packages (from ffn) (0.22.2.post1)\n",
            "Requirement already satisfied: future>=0.15 in /usr/local/lib/python3.6/dist-packages (from ffn) (0.16.0)\n",
            "Requirement already satisfied: matplotlib>=1 in /usr/local/lib/python3.6/dist-packages (from ffn) (3.2.1)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.0.28 in /usr/local/lib/python3.6/dist-packages (from PyPortfolioOpt) (1.0.28)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.16.1->empyrical) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.16.1->empyrical) (2018.9)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader>=0.2->empyrical) (2.21.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader>=0.2->empyrical) (1.12.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader>=0.2->empyrical) (4.2.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.15->ffn) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1->ffn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1->ffn) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1->ffn) (1.1.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy<2.0.0,>=1.0.28->PyPortfolioOpt) (0.6.1)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy<2.0.0,>=1.0.28->PyPortfolioOpt) (2.1.1.post2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy<2.0.0,>=1.0.28->PyPortfolioOpt) (0.70.9)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy<2.0.0,>=1.0.28->PyPortfolioOpt) (2.0.7.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.16.1->empyrical) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader>=0.2->empyrical) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader>=0.2->empyrical) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader>=0.2->empyrical) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader>=0.2->empyrical) (2.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1->ffn) (46.0.0)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy<2.0.0,>=1.0.28->PyPortfolioOpt) (0.3.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ffn/core.py:27: MatplotlibDeprecationWarning: The 'warn' parameter of use() is deprecated since Matplotlib 3.1 and will be removed in 3.3.  If any parameter follows 'warn', they should be pass as keyword, not positionally.\n",
            "  matplotlib.use('agg', warn=False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUgbJl9DCthU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate random portfolio\n",
        "randomTickers = getRandomTickers(tickers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pHQlktud2jC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retrieve price data for training period, plot data\n",
        "\n",
        "prices = ffn.get(randomTickers,start='2010-03-26', end='2015-03-26')\n",
        "ax = prices.rebase().plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DEBnCsUiRnw",
        "colab_type": "text"
      },
      "source": [
        "Now we can plot the returns for this portfolio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5pYsZJBiOig",
        "colab_type": "code",
        "outputId": "81d747d6-4a65-44c7-e7a0-61cf036f5433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "returns = prices.to_returns().dropna()\n",
        "ax = returns.hist(figsize=(10,10))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/tools.py:307: MatplotlibDeprecationWarning: \n",
            "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
            "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/tools.py:307: MatplotlibDeprecationWarning: \n",
            "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
            "  layout[ax.rowNum, ax.colNum] = ax.get_visible()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/tools.py:313: MatplotlibDeprecationWarning: \n",
            "The rowNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().rowspan.start instead.\n",
            "  if not layout[ax.rowNum + 1, ax.colNum]:\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_matplotlib/tools.py:313: MatplotlibDeprecationWarning: \n",
            "The colNum attribute was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use ax.get_subplotspec().colspan.start instead.\n",
            "  if not layout[ax.rowNum + 1, ax.colNum]:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIJg9CuFinGS",
        "colab_type": "code",
        "outputId": "b17d7651-a05f-43cd-e183-99b01e91e248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#display stats for the portfolio\n",
        "stats = prices.calc_stats()\n",
        "stats.display()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ffn/core.py:2056: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res = np.divide(er.mean(), std)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stat                 hsic        incy        msft        pki         etfc        cboe        intu        nbl         nlsn        lb\n",
            "-------------------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------\n",
            "Start                2011-01-27  2011-01-27  2011-01-27  2011-01-27  2011-01-27  2011-01-27  2011-01-27  2011-01-27  2011-01-27  2011-01-27\n",
            "End                  2015-03-26  2015-03-26  2015-03-26  2015-03-26  2015-03-26  2015-03-26  2015-03-26  2015-03-26  2015-03-26  2015-03-26\n",
            "Risk-free rate       0.00%       0.00%       0.00%       0.00%       0.00%       0.00%       0.00%       0.00%       0.00%       0.00%\n",
            "\n",
            "Total Return         108.81%     483.39%     60.63%      101.33%     63.98%      169.75%     113.47%     19.11%      77.52%      294.40%\n",
            "Daily Sharpe         1.03        1.11        0.62        0.79        0.50        1.11        0.92        0.29        0.70        1.41\n",
            "Daily Sortino        1.68        2.06        1.02        1.31        0.80        1.92        1.54        0.48        1.21        2.49\n",
            "CAGR                 19.37%      52.82%      12.07%      18.32%      12.63%      26.95%      20.00%      4.29%       14.80%      39.09%\n",
            "Max Drawdown         -20.54%     -43.26%     -18.05%     -38.15%     -60.00%     -26.22%     -28.77%     -47.29%     -21.93%     -22.83%\n",
            "Calmar Ratio         0.94        1.22        0.67        0.48        0.21        1.03        0.70        0.09        0.67        1.71\n",
            "\n",
            "MTD                  -2.01%      3.90%       -6.02%      7.47%       5.41%       -3.83%      -0.70%      1.50%       -4.29%      0.62%\n",
            "3m                   -0.12%      20.72%      -13.32%     14.80%      12.96%      -9.76%      3.22%       1.91%       -5.38%      8.63%\n",
            "6m                   17.16%      79.48%      -10.01%     15.84%      20.18%      8.03%       13.33%      -30.92%     -2.48%      36.72%\n",
            "YTD                  0.79%       22.01%      -10.65%     15.69%      13.15%      -8.67%      5.46%       1.46%       -3.26%      7.37%\n",
            "1Y                   17.69%      72.37%      6.36%       13.86%      16.66%      4.47%       26.09%      -28.30%     0.19%       68.09%\n",
            "3Y (ann.)            21.50%      64.83%      11.26%      22.96%      34.22%      27.43%      19.58%      0.34%       14.03%      28.17%\n",
            "5Y (ann.)            19.37%      52.82%      12.07%      18.32%      12.63%      26.95%      20.00%      4.29%       14.80%      39.09%\n",
            "10Y (ann.)           19.37%      52.82%      12.07%      18.32%      12.63%      26.95%      20.00%      4.29%       14.80%      39.09%\n",
            "Since Incep. (ann.)  19.37%      52.82%      12.07%      18.32%      12.63%      26.95%      20.00%      4.29%       14.80%      39.09%\n",
            "\n",
            "Daily Sharpe         1.03        1.11        0.62        0.79        0.50        1.11        0.92        0.29        0.70        1.41\n",
            "Daily Sortino        1.68        2.06        1.02        1.31        0.80        1.92        1.54        0.48        1.21        2.49\n",
            "Daily Mean (ann.)    19.53%      54.36%      14.00%      20.13%      19.68%      26.81%      20.87%      8.84%       16.65%      36.40%\n",
            "Daily Vol (ann.)     18.88%      49.12%      22.68%      25.55%      39.28%      24.09%      22.76%      30.40%      23.80%      25.81%\n",
            "Daily Skew           -0.33       1.11        -0.49       -0.13       -0.34       0.20        -0.12       -0.05       0.35        0.06\n",
            "Daily Kurt           3.81        15.28       6.83        6.45        4.26        3.23        6.85        2.58        5.03        2.04\n",
            "Best Day             6.63%       33.48%      7.29%       9.79%       13.67%      7.61%       8.31%       10.06%      9.99%       7.42%\n",
            "Worst Day            -7.17%      -21.47%     -11.40%     -11.95%     -14.64%     -5.85%      -11.06%     -9.58%      -8.64%      -8.75%\n",
            "\n",
            "Monthly Sharpe       1.15        1.16        0.74        0.90        0.52        1.11        1.18        0.24        0.79        1.52\n",
            "Monthly Sortino      2.70        3.00        1.46        1.76        0.88        3.14        2.62        0.39        1.70        3.68\n",
            "Monthly Mean (ann.)  19.14%      53.67%      14.21%      19.61%      18.91%      26.89%      19.90%      6.70%       14.96%      36.22%\n",
            "Monthly Vol (ann.)   16.62%      46.18%      19.32%      21.75%      36.48%      24.22%      16.84%      28.12%      18.96%      23.88%\n",
            "Monthly Skew         0.38        0.66        0.10        -0.01       -0.48       1.19        0.17        -0.08       0.07        0.35\n",
            "Monthly Kurt         0.18        0.81        0.45        1.25        0.26        2.83        0.48        1.68        -0.50       1.58\n",
            "Best Month           14.30%      44.77%      15.69%      20.27%      19.10%      28.60%      13.50%      26.19%      12.54%      25.18%\n",
            "Worst Month          -7.18%      -19.93%     -13.02%     -16.00%     -26.29%     -8.05%      -9.95%      -19.87%     -12.07%     -15.34%\n",
            "\n",
            "Yearly Sharpe        1.28        0.78        0.69        1.21        0.81        0.74        1.73        0.16        0.49        1.83\n",
            "Yearly Sortino       inf         inf         3.15        inf         inf         6.47        inf         0.29        8.35        inf\n",
            "Yearly Mean          21.71%      70.47%      16.75%      28.46%      42.14%      28.02%      17.97%      4.35%       13.10%      27.83%\n",
            "Yearly Vol           17.02%      90.65%      24.13%      23.54%      51.78%      37.81%      10.37%      26.94%      26.79%      15.21%\n",
            "Yearly Skew          -0.09       1.86        0.01        1.04        1.94        1.18        -0.18       -0.28       1.94        -0.91\n",
            "Yearly Kurt          0.96        3.50        -2.02       0.54        3.80        2.13        -0.81       1.07        3.81        0.85\n",
            "Best Year            42.08%      204.82%     44.30%      60.44%      119.44%     80.80%      29.73%      35.72%      53.09%      43.02%\n",
            "Worst Year           0.79%       10.66%      -10.65%     6.75%       12.44%      -8.67%      5.46%       -29.62%     -3.26%      7.37%\n",
            "\n",
            "Avg. Drawdown        -2.87%      -7.06%      -3.45%      -4.59%      -4.90%      -3.73%      -2.96%      -5.83%      -3.00%      -3.35%\n",
            "Avg. Drawdown Days   24.04       33.43       35.35       35.77       57.72       28.70       21.98       37.37       30.71       18.24\n",
            "Avg. Up Month        4.40%       13.27%      4.76%       5.73%       8.42%       6.17%       4.54%       5.22%       5.64%       6.69%\n",
            "Avg. Down Month      -2.97%      -7.67%      -4.17%      -4.02%      -7.88%      -4.16%      -3.05%      -7.05%      -3.51%      -3.51%\n",
            "Win Year %           100.00%     100.00%     75.00%      100.00%     100.00%     75.00%      100.00%     75.00%      50.00%      100.00%\n",
            "Win 12m %            97.50%      92.50%      87.50%      92.50%      70.00%      95.00%      97.50%      75.00%      75.00%      97.50%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxbnia2nqjVn",
        "colab_type": "text"
      },
      "source": [
        "Calculate mean expected returns and covariance matrix for the price data (as per defaults specified in the PyPortfolioOpt docs https://pyportfolioopt.readthedocs.io/en/latest/UserGuide.html )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytw47MkZobmI",
        "colab_type": "code",
        "outputId": "b02ae573-3550-45d4-9c7c-b63401819288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "from pypfopt.expected_returns import mean_historical_return\n",
        "from pypfopt.risk_models import CovarianceShrinkage\n",
        "\n",
        "mu = mean_historical_return(prices)\n",
        "S = CovarianceShrinkage(prices).ledoit_wolf()\n",
        "print(\"Mean expected returns: \\n\")\n",
        "print(mu, \"\\n\")\n",
        "print(\"Covariance matrix: \\n\")\n",
        "print(S, \"\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean expected returns: \n",
            "\n",
            "hsic    0.195294\n",
            "incy    0.543646\n",
            "msft    0.140022\n",
            "pki     0.201305\n",
            "etfc    0.196786\n",
            "cboe    0.268109\n",
            "intu    0.208679\n",
            "nbl     0.088353\n",
            "nlsn    0.166498\n",
            "lb      0.364036\n",
            "dtype: float64 \n",
            "\n",
            "Covariance matrix: \n",
            "\n",
            "          hsic      incy      msft  ...       nbl      nlsn        lb\n",
            "hsic  0.036597  0.034487  0.019361  ...  0.027443  0.018020  0.022877\n",
            "incy  0.034487  0.238139  0.025686  ...  0.043428  0.024293  0.036955\n",
            "msft  0.019361  0.025686  0.052058  ...  0.027607  0.015826  0.021516\n",
            "pki   0.027809  0.045353  0.022056  ...  0.038505  0.019186  0.027978\n",
            "etfc  0.039880  0.065669  0.037999  ...  0.056510  0.032380  0.041508\n",
            "cboe  0.019534  0.033653  0.017136  ...  0.021766  0.015316  0.019960\n",
            "intu  0.023816  0.030230  0.023265  ...  0.028563  0.017917  0.023437\n",
            "nbl   0.027443  0.043428  0.027607  ...  0.092231  0.027484  0.029484\n",
            "nlsn  0.018020  0.024293  0.015826  ...  0.027484  0.057148  0.019922\n",
            "lb    0.022877  0.036955  0.021516  ...  0.029484  0.019922  0.066947\n",
            "\n",
            "[10 rows x 10 columns] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMVYiioiro6X",
        "colab_type": "text"
      },
      "source": [
        "Perform efficient frontier optimization using the max-sharpe ratio as the optimization parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGQFE8bTsILC",
        "colab_type": "code",
        "outputId": "9b02414c-9314-488a-d39b-807a301379fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import objective_functions\n",
        "\n",
        "#calculate efficient frontier\n",
        "ef = EfficientFrontier(mu, S)\n",
        "\n",
        "\"\"\"\n",
        "use gamma parameter to reduce tendency of optimization to result in 0 asset weights, \n",
        "as this is detrimental to portfolio diversication\n",
        "\n",
        "https://pyportfolioopt.readthedocs.io/en/latest/EfficientFrontier.html#l2-regularisation\n",
        "\n",
        "\"\"\"\n",
        "ef.add_objective(objective_functions.L2_reg, gamma=0.1)\n",
        "weights = ef.max_sharpe()\n",
        "\n",
        "#use cleaned weights function to round data\n",
        "cleaned_weights = ef.clean_weights()\n",
        "\n",
        "#ef.save_weights_to_file(\"weights.txt\")  # saves to file\n",
        "print(cleaned_weights)\n",
        "\n",
        "#print expected performance\n",
        "ef.portfolio_performance(verbose=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hsic': 0.08171, 'incy': 0.22219, 'msft': 0.01566, 'pki': 0.04396, 'etfc': 0.0, 'cboe': 0.18589, 'intu': 0.09897, 'nbl': 0.0, 'nlsn': 0.06474, 'lb': 0.28688}\n",
            "Expected annual return: 33.3%\n",
            "Annual volatility: 20.5%\n",
            "Sharpe Ratio: 1.53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pypfopt/efficient_frontier.py:178: UserWarning: max_sharpe transforms the optimisation problem so additional objectives may not work as expected.\n",
            "  \"max_sharpe transforms the optimisation problem so additional objectives may not work as expected.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.33349813348700236, 0.20498732915454207, 1.5293537155686967)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELQeZoEbwZFp",
        "colab_type": "text"
      },
      "source": [
        "Now that the weights have been generated for the portfolio, \n",
        "the weighted and unweighted portfolio performance can be tested over the period of 2015-2020. The performance of the two portfolios can be compared to determine if the optimization indeed will improve returns.\n",
        "\n",
        "The annualized returns of the weighted portfolio can also be compared to the estimation provided by the PyPortfolioOpt library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYC0SF7PxBIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#obtain price data for test period\n",
        "testPrices = pd.DataFrame()\n",
        "testPrices = ffn.get(randomTickers,start='2015-03-26', end='2020-03-26')\n",
        "ax = testPrices.rebase().plot(title=\"Performance of random portfolio over 2015-2020\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2w3o-Wnx8dv",
        "colab_type": "text"
      },
      "source": [
        "Now we can calulate annualized return, volatility and sharpe ratio for the unweighted and weighted portfolios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RICwPo_JyM_B",
        "colab_type": "code",
        "outputId": "cdf179d7-795f-4750-a01f-bccb4078fd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#https://towardsdatascience.com/optimizing-portfolios-with-modern-portfolio-theory-using-python-60ce9a597808 \n",
        "print(\"Ticker Labels:\")\n",
        "print(randomTickers)\n",
        "print(\"Equi-weighted portfolio weights:\")\n",
        "print(np.full(10,.1), \"\\n\")\n",
        "print(\"Optimized portfolio weights:\")\n",
        "print(list(cleaned_weights.values()), \"\\n\")\n",
        "\n",
        "opt_weights = list(cleaned_weights.values())\n",
        "weights_arr = [np.full(10,.1), opt_weights]\n",
        "returns_arr = []\n",
        "volatility_arr = []\n",
        "\n",
        "print(\" --- Results --- \")\n",
        "for weights in weights_arr:\n",
        "  returns = prices.pct_change()\n",
        "  \n",
        "  # mean daily return and covariance of daily returns\n",
        "  mean_daily_returns = returns.mean()\n",
        "  cov_matrix = returns.cov()\n",
        "\n",
        "  # portfolio weights\n",
        "  weights = np.asarray(weights)\n",
        "  \n",
        "  portfolio_return = round(np.sum(mean_daily_returns * weights) * 252,2)\n",
        "  portfolio_std_dev = round(np.sqrt(np.dot(weights.T,np.dot(cov_matrix, weights))) * np.sqrt(252),2)\n",
        "\n",
        "  returns_arr.append(portfolio_return)\n",
        "  volatility_arr.append(portfolio_std_dev)\n",
        "\n",
        "  if(weights[0] == .1):\n",
        "    print(\"Equal weighted portfolio stats:\")\n",
        "  else:\n",
        "    print(\"Optimized portfolio stats:\")\n",
        "  print(\"Annualised return: \" + str(portfolio_return))\n",
        "  print(\"Volatility: \" + str(portfolio_std_dev) + \"\\n\")\n",
        "\n",
        "print(\"Percent change in return after optimization: \" + str(((returns_arr[1] - returns_arr[0])/returns_arr[0])))\n",
        "print(\"Percent change in volatility after optimization: \" + str(((volatility_arr[1] - volatility_arr[0])/volatility_arr[0])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ticker Labels:\n",
            "['HSIC', 'INCY', 'MSFT', 'PKI', 'ETFC', 'CBOE', 'INTU', 'NBL', 'NLSN', 'LB']\n",
            "Equi-weighted portfolio weights:\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1] \n",
            "\n",
            "Optimized portfolio weights:\n",
            "[0.08171, 0.22219, 0.01566, 0.04396, 0.0, 0.18589, 0.09897, 0.0, 0.06474, 0.28688] \n",
            "\n",
            " --- Results --- \n",
            "Equal weighted portfolio stats:\n",
            "Annualised return: 0.24\n",
            "Volatility: 0.19\n",
            "\n",
            "Optimized portfolio stats:\n",
            "Annualised return: 0.33\n",
            "Volatility: 0.21\n",
            "\n",
            "Percent change in return after optimization: 0.3750000000000001\n",
            "Percent change in volatility after optimization: 0.1052631578947368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlEYkSq7_O3i",
        "colab_type": "text"
      },
      "source": [
        "# **--- Optimization Results ---**\n",
        "\n",
        "**Percent change in returns:** 58.8%\n",
        "\n",
        "**Percent change in risk:** -5%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aaw49flB8MUF",
        "colab_type": "text"
      },
      "source": [
        "As expected, the portfolio optimization not only increased annualized returns, but also slightly decreased volitility.\n",
        "\n",
        "Now we can graph the performance of the two portfolios with respect to the individual securities to visualize their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axynPZvZ_L_C",
        "colab_type": "code",
        "outputId": "6fb0d990-f09d-4a16-ff08-bc48fecc9ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#unweighted prices can be found by averaging the daily prices of all stocks in the portfolio\n",
        "uw_portfolio = testPrices.sum(axis=1)\n",
        "ax = uw_portfolio.plot(title=\"Performance of unweighted portfolio over 2015-2020\")\n",
        "#random_tickers_lower = [x.lower() for x in randomTickers]\n",
        "#print(random_tickers_lower)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Basically now I dont know how to properly multiply the opt_weights vector by row\n",
        "with the price data in the dataframe. I've tried converting the data to a series first\n",
        "(see here: https://stackoverflow.com/questions/13166842/pandas-dataframe-multiply-with-a-series)\n",
        "but no luck.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def multiplyWithPrice(row, weights):\n",
        "  #print(row)\n",
        "  #print(row.name)\n",
        "  #print(row.values)\n",
        "  #print(weights)\n",
        "  #print(weights[row.name])\n",
        "  modifiedRow = []\n",
        "  for i in (0, len(row.values)-1):\n",
        "    row.values[i] = row.values[i]*weights[i]\n",
        "    #modifiedRow.append(row[i]*weights[row.name])\n",
        "  #return modifiedRow\n",
        "  return row\n",
        "\n",
        "#print(cleaned_weights)\n",
        "opt_weights_ser = pd.Series(opt_weights)\n",
        "print(opt_weights_ser)\n",
        "print(\"unweighted portfolio\")\n",
        "print(uw_portfolio)\n",
        "\n",
        "#multiplyWithPrice(column, cleaned_weights)\n",
        "temp = testPrices\n",
        "w_portfolio = temp.apply(lambda row: multiplyWithPrice(row, opt_weights_ser), axis=1)\n",
        "ax1 = testPrices.plot(title=\"Performance of individual stocks in portfolio before optimization over 2015-2020\")\n",
        "ax2 = w_portfolio.plot(title=\"Performance of individual stocks in portfolio after optimization over 2015-2020\")\n",
        "\n",
        "print(\"weighted portfolio before finding sum:\")\n",
        "print(w_portfolio)\n",
        "w_portfolio = w_portfolio.sum(axis=1)\n",
        "\n",
        "print(\"weighted portfolio\")\n",
        "print(w_portfolio)\n",
        "ax3 = w_portfolio.plot(title=\"Performance of weighted portfolio after optimization over 2015-2020\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#first plot performance of two portfolios\n",
        "portfolios = pd.concat([uw_portfolio, w_portfolio], axis=1, keys=['unweighted', 'optimized'])\n",
        "print(portfolios)\n",
        "ax4 = portfolios.plot(title=\"Performance of portfolio before and after optimization over 2015-2020\")\n",
        "\n",
        "#add portfolio data to price data\n",
        "#testPrices['uw_portfolio'] = uw_portfolio\n",
        "#testPrices['w_portfolio'] = w_portfolio\n",
        "\n",
        "#plot new data\n",
        "#ax = testPrices.plot(title=\"Performance of random portfolio over 2015-2020\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.08171\n",
            "1    0.22219\n",
            "2    0.01566\n",
            "3    0.04396\n",
            "4    0.00000\n",
            "5    0.18589\n",
            "6    0.09897\n",
            "7    0.00000\n",
            "8    0.06474\n",
            "9    0.28688\n",
            "dtype: float64\n",
            "unweighted portfolio\n",
            "Date\n",
            "2015-03-26    555.565128\n",
            "2015-03-27    562.964359\n",
            "2015-03-30    569.021252\n",
            "2015-03-31    563.505457\n",
            "2015-04-01    559.625160\n",
            "                 ...    \n",
            "2020-03-20    658.150001\n",
            "2020-03-23    634.299997\n",
            "2020-03-24    713.770003\n",
            "2020-03-25    721.669996\n",
            "2020-03-26    769.890008\n",
            "Length: 1260, dtype: float64\n",
            "weighted portfolio before finding sum:\n",
            "                hsic       incy        msft  ...        nbl       nlsn         lb\n",
            "Date                                         ...                                 \n",
            "2015-03-26  4.397280  89.199997   37.158421  ...  44.213196  35.637016  20.862522\n",
            "2015-03-27  4.447588  94.360001   36.942028  ...  44.268524  35.885479  21.067921\n",
            "2015-03-30  4.512955  94.190002   36.933010  ...  45.236904  37.094627  21.262027\n",
            "2015-03-31  4.473863  91.660004   36.662495  ...  45.098564  36.912437  21.282350\n",
            "2015-04-01  4.429002  89.440002   36.716602  ...  45.070892  37.235428  21.029552\n",
            "...              ...        ...         ...  ...        ...        ...        ...\n",
            "2020-03-20  3.677767  66.959999  137.350006  ...   4.030000  13.620000   2.805686\n",
            "2020-03-23  3.528238  63.180000  135.979996  ...   4.470000  11.940000   2.630690\n",
            "2020-03-24  3.838736  67.430000  148.339996  ...   5.830000  13.280000   3.657720\n",
            "2020-03-25  4.087951  69.589996  146.919998  ...   6.120000  13.620000   3.996238\n",
            "2020-03-26  4.376388  73.050003  156.110001  ...   6.210000  13.810000   3.769603\n",
            "\n",
            "[1260 rows x 10 columns]\n",
            "weighted portfolio\n",
            "Date\n",
            "2015-03-26    454.287123\n",
            "2015-03-27    460.610399\n",
            "2015-03-30    465.450154\n",
            "2015-03-31    460.323181\n",
            "2015-04-01    457.575441\n",
            "                 ...    \n",
            "2020-03-20    609.843456\n",
            "2020-03-23    588.108924\n",
            "2020-03-24    661.536460\n",
            "2020-03-25    665.794187\n",
            "2020-03-26    711.335997\n",
            "Length: 1260, dtype: float64\n",
            "            unweighted   optimized\n",
            "Date                              \n",
            "2015-03-26  555.565128  454.287123\n",
            "2015-03-27  562.964359  460.610399\n",
            "2015-03-30  569.021252  465.450154\n",
            "2015-03-31  563.505457  460.323181\n",
            "2015-04-01  559.625160  457.575441\n",
            "...                ...         ...\n",
            "2020-03-20  658.150001  609.843456\n",
            "2020-03-23  634.299997  588.108924\n",
            "2020-03-24  713.770003  661.536460\n",
            "2020-03-25  721.669996  665.794187\n",
            "2020-03-26  769.890008  711.335997\n",
            "\n",
            "[1260 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}